<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-10-11T11:14:29+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "ta"
}
-->
# மீட்பு மேம்படுத்தப்பட்ட உருவாக்கம் (RAG) மற்றும் வெக்டர் தரவுத்தொகுப்புகள்

[![மீட்பு மேம்படுத்தப்பட்ட உருவாக்கம் (RAG) மற்றும் வெக்டர் தரவுத்தொகுப்புகள்](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.ta.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

தேடல் பயன்பாடுகள் பாடத்தில், உங்கள் சொந்த தரவை பெரிய மொழி மாதிரிகளில் (LLMs) ஒருங்கிணைப்பது எப்படி என்பதை சுருக்கமாக கற்றுக்கொண்டோம். இந்த பாடத்தில், உங்கள் LLM பயன்பாட்டில் உங்கள் தரவை அடிப்படையாகக் கொண்டு செயல்முறையின் இயந்திரங்கள் மற்றும் தரவைச் சேமிக்கும் முறைகள், குறிப்பாக எம்பெடிங்ஸ் மற்றும் உரை ஆகியவற்றை மேலும் விரிவாக ஆராய்வோம்.

> **வீடியோ விரைவில் வரும்**

## அறிமுகம்

இந்த பாடத்தில் நாம் பின்வருவனவற்றை கற்கப்போகிறோம்:

- RAG என்றால் என்ன, அது என்னவாகும் மற்றும் ஏன் AI (artificial intelligence) இல் பயன்படுத்தப்படுகிறது என்பதை அறிதல்.

- வெக்டர் தரவுத்தொகுப்புகள் என்றால் என்ன என்பதைப் புரிந்துகொள்வது மற்றும் எங்கள் பயன்பாட்டிற்காக ஒன்றை உருவாக்குவது.

- RAG ஐ ஒரு பயன்பாட்டில் ஒருங்கிணைப்பதற்கான ஒரு நடைமுறை எடுத்துக்காட்டு.

## கற்றல் நோக்கங்கள்

இந்த பாடத்தை முடித்த பிறகு, நீங்கள்:

- தரவின் மீட்பு மற்றும் செயலாக்கத்தில் RAG இன் முக்கியத்துவத்தை விளக்கவும்.

- RAG பயன்பாட்டை அமைத்து உங்கள் தரவை LLM க்கு அடிப்படையாக அமைக்கவும்.

- LLM பயன்பாடுகளில் RAG மற்றும் வெக்டர் தரவுத்தொகுப்புகளை திறமையாக ஒருங்கிணைக்கவும்.

## எங்கள் சூழ்நிலை: எங்கள் LLM களை எங்கள் சொந்த தரவுடன் மேம்படுத்துதல்

இந்த பாடத்திற்காக, கல்வி தொடக்க நிறுவனத்தில் எங்கள் சொந்த குறிப்புகளைச் சேர்க்க விரும்புகிறோம், இது சாட்பாட்டுக்கு பல்வேறு பாடங்கள் பற்றிய கூடுதல் தகவல்களைப் பெற அனுமதிக்கிறது. எங்களிடம் உள்ள குறிப்புகளைப் பயன்படுத்தி, கற்றுக்கொள்பவர்கள் சிறந்த முறையில் படிக்கவும், பல்வேறு தலைப்புகளைப் புரிந்துகொள்ளவும் முடியும், இது அவர்களின் தேர்வுகளுக்கான மறுபார்வையை எளிதாக்கும். எங்கள் சூழ்நிலையை உருவாக்க, நாங்கள் பின்வருவனவற்றைப் பயன்படுத்துவோம்:

- `Azure OpenAI:` எங்கள் சாட்பாட்டை உருவாக்க நாங்கள் பயன்படுத்தும் LLM

- `AI for beginners' lesson on Neural Networks`: இது எங்கள் LLM க்கு அடிப்படையாக இருக்கும் தரவு

- `Azure AI Search` மற்றும் `Azure Cosmos DB:` எங்கள் தரவுகளைச் சேமிக்கவும் தேடல் குறியீட்டை உருவாக்கவும் பயன்படுத்தப்படும் வெக்டர் தரவுத்தொகுப்பு

பயனர்கள் தங்கள் குறிப்புகளிலிருந்து பயிற்சி வினாடி வினாக்களை உருவாக்கவும், மறுபார்வை ஃபிளாஷ் கார்டுகளை உருவாக்கவும் மற்றும் அதை சுருக்கமான கண்ணோட்டமாக சுருக்கவும் முடியும். தொடங்க, RAG என்ன மற்றும் அது எப்படி செயல்படுகிறது என்பதைப் பார்ப்போம்:

## மீட்பு மேம்படுத்தப்பட்ட உருவாக்கம் (RAG)

ஒரு LLM இயக்கப்படும் சாட்பாட் பயனர் உத்தேசங்களை செயலாக்கி பதில்களை உருவாக்குகிறது. இது தொடர்புடையதாக வடிவமைக்கப்பட்டுள்ளது மற்றும் பல்வேறு தலைப்புகளில் பயனர்களுடன் ஈடுபடுகிறது. இருப்பினும், அதன் பதில்கள் வழங்கப்பட்ட சூழ்நிலைக்கும் அதன் அடிப்படை பயிற்சி தரவுக்கும் மட்டுமே வரையறுக்கப்பட்டுள்ளன. உதாரணமாக, GPT-4 இன் அறிவு வெட்டுப்புள்ளி செப்டம்பர் 2021 ஆகும், அதாவது, இந்த காலகட்டத்திற்குப் பிறகு நிகழ்ந்த நிகழ்வுகள் பற்றிய அறிவு இல்லாமல் இருக்கும். கூடுதலாக, LLM களைப் பயிற்றுவிக்க பயன்படுத்தப்படும் தரவுகள் தனிப்பட்ட குறிப்புகள் அல்லது ஒரு நிறுவனத்தின் தயாரிப்பு கையேடு போன்ற ரகசிய தகவல்களை தவிர்க்கின்றன.

### RAGs (மீட்பு மேம்படுத்தப்பட்ட உருவாக்கம்) எப்படி செயல்படுகிறது

![RAGs எப்படி செயல்படுகிறது என்பதை காட்டும் வரைதல்](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.ta.png)

உங்கள் குறிப்புகளிலிருந்து வினாடி வினாக்களை உருவாக்கும் சாட்பாட்டை நீங்கள் பயன்படுத்த விரும்பினால், நீங்கள் அறிவு அடிப்படையுடன் ஒரு இணைப்பை தேவைப்படும். இதுதான் RAG உதவிக்கு வரும் இடம். RAGs பின்வருமாறு செயல்படுகிறது:

- **அறிவு அடிப்படை:** மீட்பு செய்யும் முன், இந்த ஆவணங்கள் உட்கொண்டு முன் செயலாக்கப்பட வேண்டும், பொதுவாக பெரிய ஆவணங்களை சிறிய துண்டுகளாக உடைக்க, அவற்றை உரை எம்பெடிங் ஆக மாற்றி தரவுத்தொகுப்பில் சேமிக்க வேண்டும்.

- **பயனர் கேள்வி:** பயனர் ஒரு கேள்வியை கேட்கிறார்

- **மீட்பு:** பயனர் ஒரு கேள்வியை கேட்டால், எம்பெடிங் மாடல் எங்கள் அறிவு அடிப்படையிலிருந்து தொடர்புடைய தகவல்களை மீட்டெடுத்து, அது உத்தேசத்தில் சேர்க்கப்படும் மேலும் தகவல்களை வழங்குகிறது.

- **மேம்படுத்தப்பட்ட உருவாக்கம்:** LLM மீட்டெடுக்கப்பட்ட தரவின் அடிப்படையில் அதன் பதிலை மேம்படுத்துகிறது. இது உருவாக்கப்பட்ட பதிலை முன் பயிற்சி தரவின் அடிப்படையில் மட்டுமல்லாமல், சேர்க்கப்பட்ட சூழ்நிலையிலிருந்து தொடர்புடைய தகவலின் அடிப்படையிலும் இருக்க அனுமதிக்கிறது. மீட்டெடுக்கப்பட்ட தரவுகள் LLM இன் பதில்களை மேம்படுத்த பயன்படுத்தப்படுகின்றன. பின்னர் LLM பயனர் கேள்விக்கு பதிலளிக்கிறது.

![RAGs கட்டமைப்பை காட்டும் வரைதல்](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.ta.png)

RAGs இன் கட்டமைப்பு இரண்டு பகுதிகளைக் கொண்ட மாற்றிகளைக் கொண்டு செயல்படுத்தப்படுகிறது: ஒரு என்கோடர் மற்றும் ஒரு டிகோடர். உதாரணமாக, ஒரு பயனர் ஒரு கேள்வியை கேட்டால், உள்ளீட்டு உரை வார்த்தைகளின் அர்த்தத்தைப் பிடிக்கும் வெக்டர்களாக 'என்கோடு' செய்யப்படுகிறது, மேலும் அந்த வெக்டர்கள் எங்கள் ஆவண குறியீட்டில் 'டிகோடு' செய்யப்படுகிறது மற்றும் பயனர் கேள்வியின் அடிப்படையில் புதிய உரையை உருவாக்குகிறது. LLM, உள்ளீடு மற்றும் வெளியீட்டை உருவாக்க என்கோடர்-டிகோடர் மாடலைப் பயன்படுத்துகிறது.

[RAG க்கான முன்மொழிந்த ஆவணத்தின் படி](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) RAG ஐ செயல்படுத்தும் போது இரண்டு அணுகுமுறைகள் உள்ளன:

- **_RAG-Sequence_** மீட்டெடுக்கப்பட்ட ஆவணங்களைப் பயன்படுத்தி பயனர் கேள்விக்கு சிறந்த சாத்தியமான பதிலை கணிக்கிறது

- **RAG-Token** ஆவணங்களைப் பயன்படுத்தி அடுத்த டோக்கனை உருவாக்குகிறது, பின்னர் அவற்றை பயனர் கேள்விக்கு பதிலளிக்க மீட்டெடுக்கிறது

### ஏன் நீங்கள் RAG களைப் பயன்படுத்த வேண்டும்? 

- **தகவல் செறிவு:** உரை பதில்கள் தற்போதையவை மற்றும் தற்போதையவை என்பதை உறுதிசெய்கிறது. எனவே, உள்துறை அறிவு அடிப்படையை அணுகுவதன் மூலம் டொமைன் குறிப்பிட்ட பணிகளில் செயல்திறனை மேம்படுத்துகிறது.

- **உண்மைத் தரவுகளை** பயன்படுத்துவதன் மூலம் சூழ்நிலையை வழங்கி பயனர் கேள்விகளுக்கு பதிலளிக்க fabrication ஐ குறைக்கிறது.

- LLM ஐ நுணுக்கமாக அமைப்பதை விட இது **செலவினம் குறைவாக** இருக்கும்.

## அறிவு அடிப்படையை உருவாக்குதல்

எங்கள் பயன்பாடு எங்கள் தனிப்பட்ட தரவின் அடிப்படையில் உள்ளது, அதாவது, AI For Beginners பாடத்திட்டத்தில் உள்ள நரம்பியல் நெட்வொர்க் பாடம்.

### வெக்டர் தரவுத்தொகுப்புகள்

வழக்கமான தரவுத்தொகுப்புகளுக்கு மாறாக, வெக்டர் தரவுத்தொகுப்பு என்பது எம்பெடட் வெக்டர்களை சேமிக்க, நிர்வகிக்க மற்றும் தேடுவதற்காக வடிவமைக்கப்பட்ட ஒரு சிறப்பு தரவுத்தொகுப்பாகும். இது ஆவணங்களின் எண் பிரதிநிதித்துவங்களை சேமிக்கிறது. தரவை எண் எம்பெடிங்களாக உடைத்தல் எங்கள் AI அமைப்பிற்கு தரவைப் புரிந்து கொள்ளவும் செயலாக்கவும் எளிதாக்குகிறது.

LLMs உள்ளீடாக ஏற்றுக்கொள்ளும் டோக்கன்களின் எண்ணிக்கைக்கு ஒரு வரம்பு உள்ளதால், எங்கள் எம்பெடிங்களை வெக்டர் தரவுத்தொகுப்புகளில் சேமிக்கிறோம். நீங்கள் முழு எம்பெடிங்களையும் ஒரு LLM க்கு அனுப்ப முடியாததால், அவற்றை துண்டுகளாக உடைக்க வேண்டும், மேலும் ஒரு பயனர் ஒரு கேள்வியை கேட்டால், கேள்விக்கு மிகவும் ஒத்ததாக இருக்கும் எம்பெடிங்களுடன் கூடிய உத்தேசம் திருப்பி அனுப்பப்படும். துண்டாக்குதல் LLM வழியாக அனுப்பப்படும் டோக்கன்களின் எண்ணிக்கையில் செலவுகளை குறைக்கிறது.

Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant மற்றும் DeepLake போன்ற பிரபலமான வெக்டர் தரவுத்தொகுப்புகள் சில. Azure CLI ஐப் பயன்படுத்தி Azure Cosmos DB மாடலை பின்வரும் கட்டளையைப் பயன்படுத்தி உருவாக்கலாம்:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### உரையிலிருந்து எம்பெடிங்களுக்குச் செல்லுதல்

எங்கள் தரவைச் சேமிக்கும்முன், அதை வெக்டர் எம்பெடிங்களாக மாற்றி தரவுத்தொகுப்பில் சேமிக்க வேண்டும். நீங்கள் பெரிய ஆவணங்களோ அல்லது நீண்ட உரைகளோ உடன் வேலை செய்கிறீர்கள் என்றால், நீங்கள் எதிர்பார்க்கும் கேள்விகளின் அடிப்படையில் அவற்றை துண்டாக்கலாம். துண்டாக்கல் வாக்கிய மட்டத்தில் அல்லது பத்தி மட்டத்தில் செய்யப்படலாம். துண்டாக்கல் சுற்றியுள்ள வார்த்தைகளிலிருந்து அர்த்தங்களை பெறுவதால், நீங்கள் ஒரு துண்டத்திற்கு சில பிற சூழ்நிலையைச் சேர்க்கலாம், உதாரணமாக, ஆவண தலைப்பைச் சேர்ப்பதன் மூலம் அல்லது துண்டத்திற்கு முன் அல்லது பிறகு சில உரைகளைச் சேர்ப்பதன் மூலம். தரவை பின்வருமாறு துண்டாக்கலாம்:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

துண்டாக்கப்பட்ட பிறகு, எங்கள் உரையை வெவ்வேறு எம்பெடிங் மாடல்களைப் பயன்படுத்தி எம்பெடிங் செய்யலாம். நீங்கள் பயன்படுத்தக்கூடிய சில மாடல்கள்: word2vec, ada-002 by OpenAI, Azure Computer Vision மற்றும் பல. நீங்கள் பயன்படுத்தும் மொழிகள், குறியாக்கப்படும் உள்ளடக்கத்தின் வகை (உரை/படங்கள்/ஆடியோ), குறியாக்கக்கூடிய உள்ளீட்டின் அளவு மற்றும் எம்பெடிங் வெளியீட்டின் நீளம் ஆகியவற்றின் அடிப்படையில் நீங்கள் பயன்படுத்த மாடலைத் தேர்ந்தெடுப்பீர்கள்.

OpenAI இன் `text-embedding-ada-002` மாடலைப் பயன்படுத்தி எம்பெடிங் செய்யப்பட்ட உரையின் ஒரு எடுத்துக்காட்டு:
![பூனை என்ற வார்த்தையின் எம்பெடிங்](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.ta.png)

## மீட்பு மற்றும் வெக்டர் தேடல்

ஒரு பயனர் ஒரு கேள்வியை கேட்டால், மீட்பாளர் அதை ஒரு வெக்டராக மாற்றி, எங்கள் ஆவண தேடல் குறியீட்டின் மூலம் உள்ளீட்டுடன் தொடர்புடைய ஆவணங்களுக்கான தொடர்புடைய வெக்டர்களைத் தேடுகிறது. முடிந்ததும், அது உள்ளீடு வெக்டர் மற்றும் ஆவண வெக்டர்களை உரையாக மாற்றி, அதை LLM வழியாக அனுப்புகிறது.

### மீட்பு

மீட்பு என்பது தேடல் அளவுகோல்களை பூர்த்தி செய்யும் ஆவணங்களை குறியீட்டிலிருந்து விரைவாக கண்டுபிடிக்க அமைப்பு முயற்சிக்கும் போது நடக்கிறது. மீட்பாளரின் நோக்கம், LLM ஐ உங்கள் தரவின் அடிப்படையில் நிலைப்படுத்த மற்றும் சூழ்நிலையை வழங்க பயன்படுத்தப்படும் ஆவணங்களைப் பெறுவது.

எங்கள் தரவுத்தொகுப்பில் தேடலைச் செய்ய பல வழிகள் உள்ளன, உதாரணமாக:

- **முக்கிய வார்த்தை தேடல்** - உரை தேடலுக்குப் பயன்படுத்தப்படுகிறது

- **சேமாண்டிக் தேடல்** - வார்த்தைகளின் அர்த்தத்தைப் பயன்படுத்துகிறது

- **வெக்டர் தேடல்** - ஆவணங்களை எம்பெடிங் மாடல்களைப் பயன்படுத்தி உரையிலிருந்து வெக்டர் பிரதிநிதித்துவங்களாக மாற்றுகிறது. மீட்பு பயனர் கேள்விக்கு மிக அருகிலுள்ள வெக்டர் பிரதிநிதித்துவங்களின் ஆவணங்களை கேள்வி செய்வதன் மூலம் செய்யப்படும்.

- **கலப்பு** - முக்கிய வார்த்தை மற்றும் வெக்டர் தேடல் இரண்டையும் இணைத்தல்.

மீட்புடன் ஒரு சவால் என்னவென்றால், தரவுத்தொகுப்பில் கேள்விக்கு ஒத்த பதில் எதுவும் இல்லாதபோது, அமைப்பு அவர்கள் பெறக்கூடிய சிறந்த தகவல்களை திருப்பி அனுப்பும், இருப்பினும், தொடர்புடையதற்கான அதிகபட்ச தூரத்தை அமைக்க அல்லது முக்கிய வார்த்தை மற்றும் வெக்டர் தேடலை இணைக்கும் கலப்பு தேடலைப் பயன்படுத்தலாம். இந்த பாடத்தில், நாங்கள் கலப்பு தேடலைப் பயன்படுத்துவோம், இது வெக்டர் மற்றும் முக்கிய வார்த்தை தேடலின் கலவையாகும். எங்கள் தரவை துண்டுகளையும் எம்பெடிங்களையும் கொண்ட நெடுவரிசைகளில் சேமிப்போம்.

### வெக்டர் ஒற்றுமை

மீட்பாளர் அறிவு தரவுத்தொகுப்பின் மூலம் ஒன்றுக்கொன்று அருகிலுள்ள எம்பெடிங்களைத் தேடுவார், மிக அருகிலுள்ள அண்டை, ஏனெனில் அவை ஒத்த உரைகள். ஒரு பயனர் ஒரு கேள்வியை கேட்டால், அது முதலில் எம்பெடிங் செய்யப்படும், பின்னர் ஒத்த எம்பெடிங்களுடன் பொருந்தும். வெவ்வேறு வெக்டர்கள் எவ்வளவு ஒத்ததாக உள்ளன என்பதை கண்டறிய பொதுவாக பயன்படுத்தப்படும் அளவீடு கோசைன் ஒற்றுமையாகும், இது இரண்டு வெக்டர்களுக்கு இடையிலான கோணத்தின் அடிப்படையில் இருக்கும்.

மற்ற மாற்றாக Euclidean distance (வெக்டர் முடிவுகளுக்கு இடையிலான நேர்கோட்ட தூரம்) மற்றும் dot product (இரண்டு வெக்டர்களின் தொடர்புடைய கூறுகளின் பெருக்கலின் மொத்தத்தை அளவிடுவது) ஆகியவற்றைப் பயன்படுத்தி ஒற்றுமையை அளவிடலாம்.

### தேடல் குறியீடு

மீட்பு செய்யும்போது, தேடலைச் செய்யும் முன் எங்கள் அறிவு அடிப்படைக்கான தேடல் குறியீட்டை உருவாக்க வேண்டும். ஒரு குறியீடு எங்கள் எம்பெடிங்களை சேமித்து, பெரிய தரவுத்தொகுப்பிலும் மிகவும் ஒத்த துண்டுகளை விரைவாக மீட்டெடுக்க முடியும். நாங்கள் எங்கள் குறியீட்டை உள்ளூர் அளவில் பின்வருமாறு உருவாக்கலாம்:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### மறுபதிவு

நீங்கள் தரவுத்தொகுப்பை கேள்வி கேட்ட பிறகு, நீங்கள் மிகவும் தொடர்புடையவற்றிலிருந்து முடிவுகளை வரிசைப்படுத்த வேண்டும். ஒரு மறுபதிவு LLM, தேடல் முடிவுகளின் தொடர்பை மேம்படுத்த இயந்திர கற்றலைப் பயன்படுத்தி அவற்றை வரிசைப்படுத்துகிறது. Azure AI Search ஐப் பயன்படுத்தி, மறுபதிவு தானாகவே உங்களுக்காக செய்யப்படும். மிக அருகிலுள்ள அண்டை பயன்படுத்தி மறுபதிவு எப்படி செயல்படுகிறது என்பதற்கான ஒரு எடுத்துக்காட்டு:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## இதை அனைத்தையும் ஒன்றாக இணைத்தல்

கடைசி படி, எங்கள் LLM ஐ கலந்துகொள்வது, எங்கள் தரவின் அடிப்படையில் நிலைப்படுத்தப்பட்ட பதில்களைப் பெற முடியும். இதை பின்வருமாறு செயல்படுத்தலாம்:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## எங்கள் பயன்பாட்டை மதிப்பீடு செய்தல்

### மதிப்பீட்டு அளவுகோல்கள்

- இயற்கையான, சரளமான மற்றும் மனிதர்களைப் போன்றதாக ஒலிக்கும் பதில்களை வழங்கும் தரம்

- தரவின் நிலைப்படுத்தல்: வழங்கப்பட்ட ஆவணங்களில் இருந்து வந்த பதிலை மதிப்பீடு செய்தல்

- தொடர்பு: பதில் கேள்வியுடன் பொருந்துமா மற்றும் தொடர்புடையதா என்பதை மதிப்பீடு செய்தல்

- சரளத்தன்மை - பதில் இலக்கண ரீதியாக அர்த்தமுள்ளதா என்பதை உறுதிப்படுத்துதல்

## RAG (மீட்பு மேம்படுத்தப்பட்ட உருவாக்கம்) மற்றும் வெக்டர் தரவுத்தொகுப்புகளைப் பயன்படுத்துவதற்கான பயன்பாட்டு வழிகள்

பின்வரும் பல்வேறு பயன்பாட்டு வழிகளில் செயல்பாட்டு அழைப்புகள் உங்கள் பயன்பாட்டை மேம்படுத்த உதவலாம்:

- கேள்வி மற்றும் பதிலளித்தல்: உங்கள் நிறுவன தரவை நிலைப்படுத்தி ஊழியர்கள் கேள்விகளை கேட்க பயன்படுத்தக்கூடிய சாட் உருவாக்குதல்.

- பரிந்துரை அமைப்புகள்: மிகவும் ஒத்த மதிப்புகளைப் பொருத்தும் ஒரு அமைப்பை உருவாக்கலாம், உதாரணமாக, திரைப்படங்கள், உணவகங்கள் மற்றும் பல.

- சாட்பாட் சேவைகள்: நீங்கள் சாட் வரலாற்றைச் சேமித்து, பயனர் தரவின் அடிப்படையில் உரையாடலை தனிப்பயனாக்கலாம்.

- வெக்டர் எம்பெடிங்களைக் கொண்டு பட தேடல், பட அங்கீகாரம் மற்றும் அசாதாரண கண்டறிதல் செய்ய பயனுள்ளதாக இருக்கும்.

## சுருக்கம்

RAG இன் அடிப்ப

---

**குறிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையைப் பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. எங்கள் தரச்செயல்முறைகளுக்கு முழு முயற்சி எடுத்தாலும், தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளவும். அதன் இயல்பான மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்கள் அல்லது தவறான விளக்கங்களுக்கு நாங்கள் பொறுப்பல்ல.