<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-10-11T11:25:13+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "ta"
}
-->
# ஜெனரேட்டிவ் AI-ஐ பொறுப்புடன் பயன்படுத்துவது

[![ஜெனரேட்டிவ் AI-ஐ பொறுப்புடன் பயன்படுத்துவது](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.ta.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _இந்த பாடத்தின் வீடியோவைப் பார்க்க மேலே உள்ள படத்தை கிளிக் செய்யவும்_

AI மற்றும் குறிப்பாக ஜெனரேட்டிவ் AI-ஐப் பயன்படுத்துவதில் fascination எளிதாக இருக்கலாம், ஆனால் அதை பொறுப்புடன் எப்படி பயன்படுத்துவது என்பதை நீங்கள் கவனிக்க வேண்டும். அவற்றின் output நியாயமானது, தீங்கு இல்லாதது போன்றவற்றை உறுதிப்படுத்துவது எப்படி என்பதையும் நீங்கள் கவனிக்க வேண்டும். இந்த அத்தியாயம் உங்களுக்கு இந்த சூழலை, கவனிக்க வேண்டிய விஷயங்களை, மற்றும் AI பயன்பாட்டை மேம்படுத்துவதற்கான செயல்பாடுகளை வழங்குவதை நோக்கமாகக் கொண்டுள்ளது.

## அறிமுகம்

இந்த பாடத்தில் நீங்கள் கற்றுக்கொள்ளப்போகிறீர்கள்:

- ஜெனரேட்டிவ் AI பயன்பாடுகளை உருவாக்கும்போது ஏன் பொறுப்பான AI-ஐ முன்னுரிமையாகக் கொள்ள வேண்டும்.
- பொறுப்பான AI-யின் முக்கியக் கொள்கைகள் மற்றும் அவை ஜெனரேட்டிவ் AI-யுடன் எப்படி தொடர்புடையவை.
- இந்த பொறுப்பான AI கொள்கைகளை செயல்படுத்துவதற்கான உத்திகள் மற்றும் கருவிகள்.

## கற்றல் இலக்குகள்

இந்த பாடத்தை முடித்த பிறகு நீங்கள் அறிந்திருப்பீர்கள்:

- ஜெனரேட்டிவ் AI பயன்பாடுகளை உருவாக்கும்போது பொறுப்பான AI-யின் முக்கியத்துவம்.
- ஜெனரேட்டிவ் AI பயன்பாடுகளை உருவாக்கும்போது பொறுப்பான AI-யின் முக்கியக் கொள்கைகளை எப்போது யோசிக்க வேண்டும் மற்றும் பயன்படுத்த வேண்டும்.
- பொறுப்பான AI-யின் கருத்தை நடைமுறைப்படுத்துவதற்கான கருவிகள் மற்றும் உத்திகள்.

## பொறுப்பான AI கொள்கைகள்

ஜெனரேட்டிவ் AI-யின் ஆர்வம் இதுவரை இல்லாத அளவுக்கு அதிகமாக உள்ளது. இந்த ஆர்வம் புதிய டெவலப்பர்கள், கவனம் மற்றும் நிதி ஆதரவை இந்த துறைக்கு கொண்டு வந்துள்ளது. இது ஜெனரேட்டிவ் AI-யை பயன்படுத்தி தயாரிப்புகள் மற்றும் நிறுவனங்களை உருவாக்க விரும்பும் அனைவருக்கும் மிகவும் நேர்மறையானது, ஆனால் நாம் பொறுப்புடன் முன்னேறுவது முக்கியம்.

இந்த பாடநெறி முழுவதும், நாங்கள் எங்கள் ஸ்டார்ட்அப் மற்றும் AI கல்வி தயாரிப்பை உருவாக்குவதில் கவனம் செலுத்துகிறோம். நாங்கள் பொறுப்பான AI-யின் கொள்கைகளைப் பயன்படுத்துவோம்: நியாயம், உள்ளடக்கம், நம்பகத்தன்மை/பாதுகாப்பு, பாதுகாப்பு மற்றும் தனியுரிமை, வெளிப்படைத்தன்மை மற்றும் பொறுப்புணர்வு. இந்த கொள்கைகளைப் பயன்படுத்தி, ஜெனரேட்டிவ் AI-யை எங்கள் தயாரிப்புகளில் எவ்வாறு பயன்படுத்துகிறோம் என்பதை ஆராய்வோம்.

## ஏன் பொறுப்பான AI-யை முன்னுரிமையாகக் கொள்ள வேண்டும்

ஒரு தயாரிப்பை உருவாக்கும்போது, உங்கள் பயனர் நலன்களை மனதில் வைத்து மனித மையமான அணுகுமுறையை எடுத்துக்கொள்வது சிறந்த முடிவுகளைத் தருகிறது.

ஜெனரேட்டிவ் AI-யின் தனித்தன்மை, பயனர்களுக்கு உதவியாக இருக்கும் பதில்கள், தகவல், வழிகாட்டுதல் மற்றும் உள்ளடக்கத்தை உருவாக்கும் திறனாகும். இது பல கையேடு நடவடிக்கைகள் இல்லாமல் செய்யப்படலாம், இது மிகவும் ஆச்சரியமான முடிவுகளை உருவாக்க முடியும். சரியான திட்டமிடல் மற்றும் உத்திகள் இல்லாமல், இது உங்கள் பயனர்களுக்கு, உங்கள் தயாரிப்புக்கு மற்றும் சமுதாயத்திற்கே தீங்கு விளைவிக்கக்கூடிய சில தீமையான முடிவுகளுக்கு வழிவகுக்கலாம்.

சில (ஆனால் எல்லாம் அல்ல) தீமையான முடிவுகளைப் பார்ப்போம்:

### ஹாலூசினேஷன்கள்

LLM ஒரு முற்றிலும் அர்த்தமற்ற அல்லது பிற தகவல் மூலங்களின் அடிப்படையில் உண்மையாக இல்லாததாக நாம் அறிந்த உள்ளடக்கத்தை உருவாக்கும் போது ஹாலூசினேஷன்கள் எனப்படும்.

எடுத்துக்காட்டாக, நாங்கள் எங்கள் ஸ்டார்ட்அப்பிற்காக ஒரு மாடலுக்கு மாணவர்கள் வரலாற்று கேள்விகளை கேட்க அனுமதிக்கும் ஒரு அம்சத்தை உருவாக்குகிறோம். ஒரு மாணவர் `Titanic-இன் ஒரே உயிர் பிழைத்தவர் யார்?` என்று கேட்கிறார்.

மாடல் கீழே உள்ள பதிலை உருவாக்குகிறது:

![Titanic-இன் ஒரே உயிர் பிழைத்தவர் யார் என்று கேட்கும் ப்ராம்ப்ட்](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(மூலம்: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

இது மிகவும் நம்பகமான மற்றும் விரிவான பதில். துரதிர்ஷ்டவசமாக, இது தவறானது. குறைந்த அளவு ஆராய்ச்சியுடன் கூட, Titanic பேரழிவில் ஒரே உயிர் பிழைத்தவர் இல்லை என்பதை ஒருவர் கண்டுபிடிக்க முடியும். இந்த தலைப்பைப் பற்றி ஆராய்ச்சி செய்யத் தொடங்கும் ஒரு மாணவருக்கு, இந்த பதில் கேள்வி கேட்கப்படாமல் உண்மையாகவும் சிகிச்சை அளிக்கப்படலாம். இதன் விளைவாக AI அமைப்பு நம்பகமற்றதாக மாறும் மற்றும் எங்கள் ஸ்டார்ட்அப்பின் மதிப்புக்கு எதிர்மறை தாக்கத்தை ஏற்படுத்தும்.

ஏதேனும் கொடுக்கப்பட்ட LLM-இன் ஒவ்வொரு iteration-இலேயும், ஹாலூசினேஷன்களை குறைப்பதில் செயல்திறன் மேம்பாடுகளை நாம் கண்டுள்ளோம். இந்த மேம்பாட்டுடன் கூட, பயன்பாடுகளை உருவாக்குபவர்கள் மற்றும் பயனர்கள் இந்த வரம்புகளைப் பற்றி விழிப்புணர்வுடன் இருக்க வேண்டும்.

### தீங்கு விளைவிக்கும் உள்ளடக்கம்

முன்னைய பிரிவில், LLM தவறான அல்லது அர்த்தமற்ற பதில்களை உருவாக்கும் போது நாம் கவனித்தோம். மற்றொரு ஆபத்து, ஒரு மாடல் தீங்கு விளைவிக்கும் உள்ளடக்கத்துடன் பதிலளிக்கும் போது.

தீங்கு விளைவிக்கும் உள்ளடக்கம் வரையறுக்கப்படலாம்:

- சுயதீங்கு அல்லது குறிப்பிட்ட குழுக்களுக்கு தீங்கு விளைவிக்க வழிகாட்டுதல் அல்லது ஊக்குவித்தல்.
- வெறுப்பான அல்லது இழிவான உள்ளடக்கம்.
- எந்தவொரு வகையான தாக்குதல் அல்லது வன்முறை செயல்களைத் திட்டமிட வழிகாட்டுதல்.
- சட்டவிரோத உள்ளடக்கத்தை கண்டுபிடிக்க அல்லது சட்டவிரோத செயல்களைச் செய்ய வழிகாட்டுதல்.
- பாலியல் விளக்கமான உள்ளடக்கத்தை காட்டுதல்.

எங்கள் ஸ்டார்ட்அப்பிற்காக, மாணவர்கள் இந்த வகையான உள்ளடக்கத்தைப் பார்க்காமல் தடுக்க சரியான கருவிகள் மற்றும் உத்திகள் உள்ளன என்பதை உறுதிப்படுத்த விரும்புகிறோம்.

### நியாயமின்மை

நியாயம் என்பது "AI அமைப்பு பாகுபாடு மற்றும் பாகுபாட்டிலிருந்து விடுபட்டது மற்றும் அனைவரையும் நியாயமாகவும் சமமாகவும் நடத்துகிறது என்பதை உறுதிப்படுத்துதல்" என்று வரையறுக்கப்படுகிறது. ஜெனரேட்டிவ் AI உலகில், மாடலின் output marginalized குழுக்களின் exclusionary worldviews-ஐ reinforcement செய்யாததை உறுதிப்படுத்த விரும்புகிறோம்.

இந்த வகையான output-கள் எங்கள் பயனர்களுக்கு நேர்மறையான தயாரிப்பு அனுபவங்களை உருவாக்குவதற்கு அழிவை ஏற்படுத்துவதோடு, மேலும் சமூகத்திற்கும் தீங்கு விளைவிக்கின்றன. பயன்பாடுகளை உருவாக்குபவர்கள், ஜெனரேட்டிவ் AI-யுடன் தீர்வுகளை உருவாக்கும்போது, ​​எப்போதும் பரந்த மற்றும் பல்வகை பயனர் அடிப்படையை மனதில் வைத்திருக்க வேண்டும்.

## ஜெனரேட்டிவ் AI-ஐ பொறுப்புடன் எப்படி பயன்படுத்துவது

இப்போது பொறுப்பான ஜெனரேட்டிவ் AI-யின் முக்கியத்துவத்தை நாங்கள் அடையாளம் கண்டுள்ளோம், AI தீர்வுகளை பொறுப்புடன் உருவாக்க 4 படிகளைப் பார்ப்போம்:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.ta.png)

### தீமைகளை அளவிடுதல்

சாப்ட்வேர் டெஸ்டிங்கில், ஒரு பயன்பாட்டில் பயனர் எதிர்பார்க்கப்படும் செயல்களை நாங்கள் சோதிக்கிறோம். அதேபோல், பயனர்கள் அதிகம் பயன்படுத்தக்கூடிய ப்ராம்ப்ட்களை பரந்த அளவில் சோதிப்பது தீமையை அளவிட நல்ல வழியாகும்.

எங்கள் ஸ்டார்ட்அப் கல்வி தயாரிப்பை உருவாக்குவதால், கல்வி தொடர்பான ப்ராம்ப்ட்களின் பட்டியலைத் தயாரிப்பது நல்லது. இது ஒரு குறிப்பிட்ட பாடத்தை, வரலாற்று உண்மைகளை மற்றும் மாணவர் வாழ்க்கை பற்றிய ப்ராம்ப்ட்களை உள்ளடக்கலாம்.

### தீமைகளை குறைக்குதல்

இப்போது மாடல் மற்றும் அதன் பதில்கள் ஏற்படுத்தும் தீமையைத் தடுக்க அல்லது வரையறுக்க வழிகளை கண்டுபிடிக்க நேரம். இதை நான்கு வெவ்வேறு அடுக்குகளில் பார்க்கலாம்:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.ta.png)

- **மாடல்**. சரியான பயன்பாட்டுக்கு சரியான மாடலைத் தேர்ந்தெடுப்பது. GPT-4 போன்ற பெரிய மற்றும் சிக்கலான மாடல்கள் சிறிய மற்றும் குறிப்பிட்ட பயன்பாடுகளில் பயன்படுத்தும்போது தீங்கு விளைவிக்கும் உள்ளடக்கத்தின் ஆபத்தை அதிகரிக்கக்கூடும். உங்கள் பயிற்சி தரவுகளைப் பயன்படுத்தி fine-tune செய்வது தீங்கு விளைவிக்கும் உள்ளடக்கத்தின் ஆபத்தை குறைக்கும்.

- **பாதுகாப்பு அமைப்பு**. பாதுகாப்பு அமைப்பு என்பது மாடலை வழங்கும் தளத்தில் உள்ள கருவிகள் மற்றும் கட்டமைப்புகளின் தொகுப்பாகும், இது தீமையை குறைக்க உதவுகிறது. இதற்கான ஒரு உதாரணம் Azure OpenAI சேவையில் உள்ள உள்ளடக்க வடிகட்டல் அமைப்பு. அமைப்புகள் jailbreak தாக்குதல்கள் மற்றும் bot-களின் கோரிக்கைகள் போன்ற தேவையற்ற செயல்பாடுகளை கண்டறிய வேண்டும்.

- **Metaprompt**. Metaprompts மற்றும் grounding என்பது குறிப்பிட்ட நடத்தை மற்றும் தகவலின் அடிப்படையில் மாடலை இயக்க அல்லது வரையறுக்க நாங்கள் செய்யக்கூடிய வழிகள். இது மாடலின் வரம்புகளை வரையறுக்க system inputs-ஐப் பயன்படுத்துவது போன்றது. கூடுதலாக, அமைப்பின் scope அல்லது domain-க்கு அதிகம் பொருந்தக்கூடிய output-களை வழங்குவது.

இது Retrieval Augmented Generation (RAG) போன்ற உத்திகளைப் பயன்படுத்தி, மாடல் நம்பகமான மூலங்களின் தேர்விலிருந்து மட்டுமே தகவலை எடுக்க அனுமதிக்கவும் இருக்கலாம். [search பயன்பாடுகளை உருவாக்குவது](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) பற்றிய பாடம் இந்த பாடநெறியில் பின்னர் உள்ளது.

- **பயனர் அனுபவம்**. இறுதி அடுக்கு என்பது பயனர் எங்கள் பயன்பாட்டின் இடைமுகத்தின் மூலம் மாடலுடன் நேரடியாக தொடர்பு கொள்ளும் இடம். இந்த வழியில், மாடலுக்கு அனுப்பக்கூடிய input-களின் வகைகளை வரையறுக்க UI/UX-ஐ வடிவமைக்கலாம், மேலும் பயனருக்கு காட்டப்படும் உரை அல்லது படங்களை வரையறுக்கலாம். AI பயன்பாட்டை deploy செய்யும்போது, ​​எங்கள் ஜெனரேட்டிவ் AI பயன்பாடு என்ன செய்ய முடியும் மற்றும் என்ன செய்ய முடியாது என்பதைப் பற்றி வெளிப்படையாக இருக்க வேண்டும்.

[AI பயன்பாடுகளுக்கான UX வடிவமைத்தல்](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) பற்றிய முழு பாடம் எங்களிடம் உள்ளது.

- **மாடலை மதிப்பீடு செய்யுங்கள்**. LLM-களுடன் வேலை செய்வது சவாலாக இருக்கலாம், ஏனெனில் மாடல் பயிற்சி அளிக்கப்பட்ட தரவின் மீது எப்போதும் நமக்கு கட்டுப்பாடு இருக்காது. இருப்பினும், மாடலின் செயல்திறன் மற்றும் output-களை எப்போதும் மதிப்பீடு செய்ய வேண்டும். மாடலின் துல்லியம், ஒற்றுமை, groundedness மற்றும் output-இன் பொருத்தம் ஆகியவற்றை அளவிடுவது இன்னும் முக்கியம். இது பங்குதாரர்கள் மற்றும் பயனர்களுக்கு வெளிப்படைத்தன்மை மற்றும் நம்பகத்தன்மையை வழங்க உதவுகிறது.

### பொறுப்பான ஜெனரேட்டிவ் AI தீர்வை இயக்குங்கள்

AI பயன்பாடுகளைச் சுற்றியுள்ள ஒரு செயல்பாட்டு நடைமுறையை உருவாக்குவது இறுதி நிலையாகும். இது அனைத்து ஒழுங்குமுறை கொள்கைகளுடன் இணங்குவதை உறுதிப்படுத்த எங்கள் ஸ்டார்ட்அப்பின் பிற பகுதிகளுடன், Legal மற்றும் Security போன்றவற்றுடன் கூட்டாண்மை செய்வதை உள்ளடக்கியது. வெளியீட்டிற்கு முன், விநியோகம், சம்பவங்களை கையாளுதல் மற்றும் rollback பற்றிய திட்டங்களை உருவாக்க விரும்புகிறோம், இது எங்கள் பயனர்களுக்கு எந்தவிதமான தீமையும் ஏற்படாமல் தடுக்க உதவும்.

## கருவிகள்

பொறுப்பான AI தீர்வுகளை உருவாக்குவது மிகவும் கடினமான வேலை என்று தோன்றினாலும், இது மிகவும் மதிப்புமிக்க முயற்சியாகும். ஜெனரேட்டிவ் AI துறையின் வளர்ச்சியுடன், டெவலப்பர்கள் பொறுப்பை தங்கள் வேலைவழிகளில் திறமையாக ஒருங்கிணைக்க உதவும் கருவிகள் மேலும் வளர்ச்சியடையும். உதாரணமாக, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) API கோரிக்கையின் மூலம் தீங்கு விளைவிக்கும் உள்ளடக்கம் மற்றும் படங்களை கண்டறிய உதவுகிறது.

## அறிவு சோதனை

பொறுப்பான AI பயன்பாட்டை உறுதிப்படுத்த நீங்கள் கவனிக்க வேண்டிய சில விஷயங்கள் என்ன?

1. பதில் சரியானது என்பதை உறுதிப்படுத்துதல்.
1. தீங்கு விளைவிக்கும் பயன்பாடு, AI குற்றவியல் நோக்கங்களுக்காக பயன்படுத்தப்படாதது.
1. AI பாகுபாடு மற்றும் பாகுபாட்டிலிருந்து விடுபட்டது என்பதை உறுதிப்படுத்துதல்.

A: 2 மற்றும் 3 சரியானவை. பொறுப்பான AI உங்களுக்கு தீங்கு விளைவிக்கும் விளைவுகளை மற்றும் பாகுபாடுகளை குறைக்க எப்படி கவனிக்க வேண்டும் என்பதைக் கருத உதவுகிறது.

## 🚀 சவால்

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) பற்றி படித்து, உங்கள் பயன்பாட்டிற்காக நீங்கள் ஏற்றுக்கொள்ளக்கூடியதைப் பாருங்கள்.

## சிறந்த வேலை, உங்கள் கற்றலை தொடருங்கள்

இந்த பாடத்தை முடித்த பிறகு, எங்கள் [ஜெனரேட்டிவ் AI கற்றல் தொகுப்பை](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) பாருங்கள், உங்கள் ஜெனரேட்டிவ் AI அறிவை மேலும் மேம்படுத்த!

Lesson 4-க்கு செல்லுங்கள், அங்கு [Prompt Engineering Fundamentals](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) பற்றி பார்ப்போம்!

---

**அறிவிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை தயவுசெய்து கவனத்தில் கொள்ளவும். அதன் சொந்த மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்களுக்கும் அல்லது தவறான விளக்கங்களுக்கும் நாங்கள் பொறுப்பல்ல.