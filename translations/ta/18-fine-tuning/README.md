<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-10-11T11:49:29+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "ta"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.ta.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# உங்கள் LLM-ஐ Fine-Tuning செய்வது

பெரிய மொழி மாதிரிகளை பயன்படுத்தி Generative AI பயன்பாடுகளை உருவாக்குவது புதிய சவால்களுடன் வருகிறது. முக்கிய பிரச்சினை, ஒரு குறிப்பிட்ட பயனர் கோரிக்கைக்கு மாதிரி உருவாக்கிய உள்ளடக்கத்தின் பதில்களின் தரத்தை (துல்லியம் மற்றும் தொடர்புடையது) உறுதிப்படுத்துவது. முந்தைய பாடங்களில், prompt engineering மற்றும் retrieval-augmented generation போன்ற தொழில்நுட்பங்களைப் பற்றி விவாதித்தோம், அவை உள்ளடக்கத்தை _மாற்றுவதன் மூலம்_ இந்த பிரச்சினையைத் தீர்க்க முயற்சிக்கின்றன.

இன்றைய பாடத்தில், **fine-tuning** என்ற மூன்றாவது தொழில்நுட்பத்தைப் பற்றி விவாதிக்கிறோம், இது _மாதிரியைத் தானாகவே மீண்டும் பயிற்சி அளிப்பதன் மூலம்_ சவால்களைத் தீர்க்க முயற்சிக்கிறது. விவரங்களில் மூழ்குவோம்.

## கற்றல் நோக்கங்கள்

இந்த பாடம் முன்பே பயிற்சி அளிக்கப்பட்ட மொழி மாதிரிகளுக்கான fine-tuning என்ற கருத்தை அறிமுகப்படுத்துகிறது, இந்த அணுகுமுறையின் நன்மைகள் மற்றும் சவால்களை ஆராய்கிறது, மேலும் உங்கள் Generative AI மாதிரிகளின் செயல்திறனை மேம்படுத்த fine-tuning ஐ எப்போது மற்றும் எப்படி பயன்படுத்துவது என்பதற்கான வழிகாட்டுதலையும் வழங்குகிறது.

இந்த பாடத்தின் முடிவில், நீங்கள் பின்வரும் கேள்விகளுக்கு பதிலளிக்க முடியும்:

- மொழி மாதிரிகளுக்கான fine-tuning என்றால் என்ன?
- Fine-tuning எப்போது, ஏன் பயனுள்ளதாக இருக்கும்?
- முன்பே பயிற்சி அளிக்கப்பட்ட மாதிரியை நான் எப்படி fine-tune செய்யலாம்?
- Fine-tuning-இன் வரம்புகள் என்ன?

தயார்? தொடங்குவோம்.

## விளக்கப்படம்

நாம் விவரங்களில் மூழ்குவதற்கு முன், இந்த பாடத்திற்கான கற்றல் பயணத்தை விளக்கும் விளக்கப்படத்தைப் பாருங்கள் - fine-tuning பற்றிய முக்கிய கருத்துகள் மற்றும் உந்துதல்களைப் புரிந்துகொள்வதிலிருந்து, fine-tuning பணியைச் செயல்படுத்துவதற்கான செயல்முறை மற்றும் சிறந்த நடைமுறைகளைப் புரிந்துகொள்வதற்கு. இது ஆராய்வதற்கான ஒரு சுவாரஸ்யமான தலைப்பாகும், எனவே உங்கள் சுய-கற்றல் பயணத்தை ஆதரிக்க கூடுதல் இணைப்புகளுக்கான [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) பக்கத்தை மறக்காமல் பாருங்கள்!

![மொழி மாதிரிகளை Fine-Tuning செய்வதற்கான விளக்கப்படம்](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.ta.png)

## மொழி மாதிரிகளுக்கான fine-tuning என்றால் என்ன?

வரையறையின்படி, பெரிய மொழி மாதிரிகள் _முன்பே பயிற்சி அளிக்கப்பட்டவை_ மற்றும் இணையம் உள்ளிட்ட பல்வேறு மூலங்களில் இருந்து பெறப்பட்ட பெரிய அளவிலான உரை தரவுகளின் அடிப்படையில் உருவாக்கப்பட்டவை. முந்தைய பாடங்களில், பயனர் கேள்விகளுக்கு ("prompts") மாதிரியின் பதில்களின் தரத்தை மேம்படுத்த _prompt engineering_ மற்றும் _retrieval-augmented generation_ போன்ற தொழில்நுட்பங்கள் தேவைப்படும் என்பதை நாம் கற்றுக்கொண்டோம்.

Prompt-engineering தொழில்நுட்பத்தில், மாதிரியின் பதிலில் என்ன எதிர்பார்க்கப்படுகிறது என்பதை மேலும் வழிகாட்டுதல் அளிப்பது பொதுவாக உள்ளது, இது _வழிகாட்டுதல்கள்_ (explicit guidance) அல்லது _சில உதாரணங்களை வழங்குவது_ (implicit guidance) மூலம் செய்யப்படுகிறது. இதை _few-shot learning_ என்று குறிப்பிடுகிறார்கள், ஆனால் இதற்கு இரண்டு வரம்புகள் உள்ளன:

- மாதிரி token வரம்புகள் நீங்கள் வழங்கக்கூடிய உதாரணங்களின் எண்ணிக்கையை மட்டுப்படுத்தலாம், மேலும் செயல்திறனை குறைக்கலாம்.
- மாதிரி token செலவுகள் ஒவ்வொரு prompt-க்கும் உதாரணங்களைச் சேர்ப்பதை விலையுயர்ந்ததாக மாற்றலாம், மேலும் flexibility-ஐ குறைக்கலாம்.

Fine-tuning என்பது இயந்திர கற்றல் அமைப்புகளில் பொதுவாக பயன்படுத்தப்படும் நடைமுறையாகும், இதில் முன்பே பயிற்சி அளிக்கப்பட்ட மாதிரியை எடுத்துக்கொண்டு புதிய தரவுகளுடன் மீண்டும் பயிற்சி அளிக்கப்படுகிறது, குறிப்பிட்ட பணியில் அதன் செயல்திறனை மேம்படுத்த. மொழி மாதிரிகளின் சூழலில், fine-tuning மூலம் **custom model** உருவாக்க முடியும், இது அந்த குறிப்பிட்ட பணி அல்லது application domain-க்கு மேலும் துல்லியமான மற்றும் தொடர்புடையதாக இருக்கலாம். Fine-tuning-இன் ஒரு பக்க நன்மை, few-shot learning-க்கு தேவையான உதாரணங்களின் எண்ணிக்கையை குறைக்கவும் முடியும் - token பயன்பாடு மற்றும் தொடர்புடைய செலவுகளை குறைக்கிறது.

## Fine-Tuning எப்போது மற்றும் ஏன் செய்ய வேண்டும்?

இந்த சூழலில், fine-tuning பற்றி பேசும்போது, **supervised** fine-tuning-ஐ குறிப்பிடுகிறோம், இதில் மீண்டும் பயிற்சி அளிப்பது **புதிய தரவுகளைச் சேர்ப்பதன் மூலம்** செய்யப்படுகிறது, இது முதன்மை பயிற்சி தரவுத்தொகுப்பில் இல்லை. இது unsupervised fine-tuning அணுகுமுறையிலிருந்து வேறுபட்டது, இதில் மாதிரி முதன்மை தரவுகளில் மீண்டும் பயிற்சி அளிக்கப்படுகிறது, ஆனால் வேறுபட்ட hyperparameters-க்களுடன்.

Fine-tuning என்பது எதிர்பார்க்கப்படும் முடிவுகளைப் பெறுவதற்கு ஒரு குறிப்பிட்ட அளவிலான நிபுணத்துவத்தைத் தேவைப்படும் மேம்பட்ட தொழில்நுட்பம் என்பதை நினைவில் கொள்ள வேண்டும். தவறாக செய்யப்படும் போது, இது எதிர்பார்க்கப்படும் மேம்பாடுகளை வழங்காது, மேலும் உங்கள் இலக்கு domain-க்கு மாதிரியின் செயல்திறனை குறைக்கக்கூடும்.

அதனால், மொழி மாதிரிகளை "எப்படி" fine-tune செய்வது என்பதை நீங்கள் கற்றுக்கொள்வதற்கு முன், "ஏன்" இந்த வழியை நீங்கள் எடுத்துக்கொள்ள வேண்டும், மற்றும் "எப்போது" fine-tuning செயல்முறையைத் தொடங்க வேண்டும் என்பதை நீங்கள் அறிந்திருக்க வேண்டும். இந்த கேள்விகளை உங்களிடம் கேளுங்கள்:

- **பயன்பாட்டு வழக்கு**: Fine-tuning-க்கு உங்கள் _பயன்பாட்டு வழக்கு_ என்ன? தற்போதைய pre-trained மாதிரியில் எந்த அம்சத்தை மேம்படுத்த விரும்புகிறீர்கள்?
- **மாற்று வழிகள்**: விரும்பிய முடிவுகளை அடைய _மற்ற தொழில்நுட்பங்களை_ நீங்கள் முயற்சித்தீர்களா? அவற்றை ஒப்பீட்டுக்கான அடிப்படையாக பயன்படுத்துங்கள்.
  - Prompt engineering: தொடர்புடைய prompt பதில்களின் உதாரணங்களுடன் few-shot prompting போன்ற தொழில்நுட்பங்களை முயற்சிக்கவும். பதில்களின் தரத்தை மதிப்பீடு செய்யவும்.
  - Retrieval Augmented Generation: உங்கள் தரவுகளைத் தேடுவதன் மூலம் பெறப்பட்ட query முடிவுகளுடன் prompts-ஐ augment செய்ய முயற்சிக்கவும். பதில்களின் தரத்தை மதிப்பீடு செய்யவும்.
- **செலவுகள்**: Fine-tuning-க்கு செலவுகளை நீங்கள் அடையாளம் கண்டுள்ளீர்களா?
  - Tunability - fine-tuning-க்கு pre-trained மாதிரி கிடைக்கிறதா?
  - முயற்சி - பயிற்சி தரவுகளைத் தயாரிக்க, மாதிரியை மதிப்பீடு & மேம்படுத்த.
  - கணினி - fine-tuning jobs-ஐ இயக்க, மற்றும் fine-tuned மாதிரியை deploy செய்ய.
  - தரவு - fine-tuning-க்கு தேவையான தரமான உதாரணங்களுக்கு அணுகல்.
- **நன்மைகள்**: Fine-tuning-க்கு நன்மைகளை நீங்கள் உறுதிப்படுத்தியுள்ளீர்களா?
  - தரம் - fine-tuned மாதிரி baseline-ஐ விட மேலானதா?
  - செலவு - prompts-ஐ எளிமைப்படுத்துவதன் மூலம் token பயன்பாட்டை குறைக்கிறதா?
  - விரிவாக்கம் - base மாதிரியை புதிய domain-களுக்கு மீண்டும் பயன்படுத்த முடியுமா?

இந்த கேள்விகளுக்கு பதிலளிப்பதன் மூலம், fine-tuning உங்கள் பயன்பாட்டு வழக்குக்கு சரியான அணுகுமுறைதானா என்பதை நீங்கள் முடிவு செய்ய முடியும். பொதுவாக, நன்மைகள் செலவுகளை விட அதிகமாக இருந்தால் மட்டுமே இந்த அணுகுமுறை செல்லுபடியாகும். நீங்கள் தொடர முடிவு செய்ததும், முன்பே பயிற்சி அளிக்கப்பட்ட மாதிரியை fine-tune செய்ய _எப்படி_ என்பதைப் பற்றி சிந்திக்க நேரம்.

முடிவெடுக்கும் செயல்முறையைப் பற்றி மேலும் தகவல்களைப் பெற விரும்புகிறீர்களா? [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs) காணுங்கள்.

## முன்பே பயிற்சி அளிக்கப்பட்ட மாதிரியை fine-tune செய்வது எப்படி?

முன்பே பயிற்சி அளிக்கப்பட்ட மாதிரியை fine-tune செய்ய, உங்களிடம் இருக்க வேண்டும்:

- fine-tune செய்ய முன்பே பயிற்சி அளிக்கப்பட்ட மாதிரி
- fine-tuning-க்கு பயன்படுத்த dataset
- fine-tuning job-ஐ இயக்க பயிற்சி சூழல்
- fine-tuned மாதிரியை deploy செய்ய hosting சூழல்

## Fine-Tuning செயல்பாட்டில்

கீழே உள்ள வளங்கள், தேர்ந்தெடுக்கப்பட்ட மாதிரி மற்றும் curated dataset-ஐ பயன்படுத்தி ஒரு உண்மையான உதாரணத்தை உங்களுடன் walkthrough செய்யும் படிப்புகளை வழங்குகின்றன. இந்த படிப்புகளைச் செயல்படுத்த, குறிப்பிட்ட வழங்குநரின் கணக்கு மற்றும் தொடர்புடைய மாதிரி மற்றும் dataset-களுக்கான அணுகல் தேவைப்படும்.

| வழங்குநர்     | படிப்பு                                                                                                                                                                       | விளக்கம்                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | `gpt-35-turbo` மாதிரியை ஒரு குறிப்பிட்ட domain ("recipe assistant")-க்கு fine-tune செய்ய கற்றல் தரவுகளைத் தயாரித்து, fine-tuning job-ஐ இயக்கி, fine-tuned மாதிரியை inference-க்கு பயன்படுத்த கற்றுக்கொள்ளுங்கள்.                                                                                                                                                                                                                                              |
| Azure OpenAI | [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | `gpt-35-turbo-0613` மாதிரியை **Azure**-ல் fine-tune செய்ய, பயிற்சி தரவுகளை உருவாக்க & upload செய்ய, fine-tuning job-ஐ இயக்குவதற்கான படிகளை எடுக்க கற்றுக்கொள்ளுங்கள். புதிய மாதிரியை deploy செய்து பயன்படுத்தவும்.                                                                                                                                                                                                                                                                 |
| Hugging Face | [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | இந்த blog post, [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) library மற்றும் [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) ஆகியவற்றைப் பயன்படுத்தி _open LLM_ (எ.கா: `CodeLlama 7B`) fine-tune செய்யும் செயல்முறையை உங்களுடன் walkthrough செய்கிறது. Hugging Face-ல் open [datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) பயன்படுத்தப்படுகிறது. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 🤗 AutoTrain | [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (அல்லது AutoTrain Advanced) என்பது Hugging Face உருவாக்கிய python library ஆகும், இது பல்வேறு பணிகளுக்கு, LLM fine-tuning உட்பட, fine-tuning செய்ய அனுமதிக்கிறது. AutoTrain ஒரு no-code தீர்வாகும், மேலும் fine-tuning உங்கள் சொந்த cloud-ல், Hugging Face Spaces-ல் அல்லது local-ல் செய்யலாம். இது web-based GUI, CLI மற்றும் yaml config files மூலம் பயிற்சியை ஆதரிக்கிறது.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## பணிக்கட்டளை

மேலே உள்ள படிப்புகளில் ஒன்றைத் தேர்ந்தெடுத்து அவற்றை walkthrough செய்யுங்கள். _இந்த repo-வில் Jupyter Notebooks-ல் இந்த படிப்புகளின் ஒரு பதிப்பை reference-only க்காக நாங்கள் மீண்டும் உருவாக்கலாம். தயவுசெய்து original sources-ஐ நேரடியாகப் பயன்படுத்தி சமீபத்திய பதிப்புகளைப் பெறுங்கள்_.

## சிறந்த வேலை! உங்கள் கற்றலைத் தொடருங்கள்.

இந்த பாடத்தை முடித்த பிறகு, [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ஐப் பாருங்கள், உங்கள் Generative AI அறிவை மேம்படுத்த தொடர்ந்து கற்றல் செய்யுங்கள்!

வாழ்த்துக்கள்!! இந்த பாடநெறிக்கான v2 தொடரின் இறுதி பாடத்தை நீங்கள் முடித்துவிட்டீர்கள்! கற்றல் மற்றும் கட்டமைப்பை நிறுத்தாதீர்கள். \*\*இந்த தலைப்புக்கான கூடுதல் பரிந்துரைகளுக்கான பட்டியலுக்காக [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) பக்கத்தைப் பாருங்கள்.

எங்கள் v1 பாடத்தொடரும் கூடுதல் பணிக்கட்டளைகள் மற்றும் கருத்துக்களுடன் புதுப்பிக்கப்பட்டுள்ளது. எனவே உங்கள் அறிவை புதுப்பிக்க ஒரு நிமிடம் எடுத்துக்கொள்ளுங்கள் - மேலும் இந்த பாடங்களை சமூகத்திற்காக மேம்படுத்த உதவ [உங்கள் கேள்விகள் மற்றும் கருத்துகளை](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) பகிரவும்.

---

**அறிவிப்பு**:  
இந்த ஆவணம் [Co-op Translator](https://github.com/Azure/co-op-translator) என்ற AI மொழிபெயர்ப்பு சேவையை பயன்படுத்தி மொழிபெயர்க்கப்பட்டுள்ளது. நாங்கள் துல்லியத்திற்காக முயற்சிக்கிறோம், ஆனால் தானியங்கி மொழிபெயர்ப்புகளில் பிழைகள் அல்லது தவறுகள் இருக்கக்கூடும் என்பதை கவனத்தில் கொள்ளவும். அதன் சொந்த மொழியில் உள்ள மூல ஆவணம் அதிகாரப்பூர்வ ஆதாரமாக கருதப்பட வேண்டும். முக்கியமான தகவல்களுக்கு, தொழில்முறை மனித மொழிபெயர்ப்பு பரிந்துரைக்கப்படுகிறது. இந்த மொழிபெயர்ப்பைப் பயன்படுத்துவதால் ஏற்படும் எந்த தவறான புரிதல்களுக்கும் அல்லது தவறான விளக்கங்களுக்கும் நாங்கள் பொறுப்பல்ல.